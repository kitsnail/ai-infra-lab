# llm-d å¿«é€Ÿå…¥é—¨æŒ‡å—

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### å‰ç½®è¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| **Kubernetes** | >= 1.29 | 1.30+ |
| **ç¡¬ä»¶** | NVIDIA A100 40GB | NVIDIA H100 80GB |
| **CPU** | 64æ ¸ + 64GB RAM | 128æ ¸ + 128GB RAM |

### ä¸€é”®éƒ¨ç½² (æ¨è)

```bash
# æ­¥éª¤1: æ¨¡å‹å‡†å¤‡
cd workspace/llm
kubectl apply -k .
kubectl exec -it llm-dev-xxx -n llm -- bash
modelscope download --model deepseek-ai/DeepSeek-V3.1 --local_dir /models/deepseek-ai/DeepSeek-V3.1
modelscope download --model Qwen/Qwen3-VL-235B-A22B-Instruct --local_dir /models/Qwen/Qwen3-VL-235B-A22B-Instruct

# æ­¥éª¤2: ä¸€é”®éƒ¨ç½²
cd workspace/llm-d-0.4.0
helmwave up --build
```

### éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥PodçŠ¶æ€
kubectl get pods -n llm-d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get svc -n llm-d

# æµ‹è¯•API
kubectl port-forward <gateway-pod> 8080:8080 -n llm-d
curl http://localhost:8080/v1/models
```

## ğŸ“‹ ä¸‰ç§éƒ¨ç½²æ¨¡å¼

### 1. æ™ºèƒ½æ¨ç†è°ƒåº¦ï¼ˆæ–°æ‰‹æ¨èï¼‰

```bash
# ä¸€é”®éƒ¨ç½²
cd workspace/llm-d-1.3.1
helmwave up --build
```

**åŒ…å«ç»„ä»¶**: EPP + Model Service + Gateway + BBR

### 2. é¢„å¡«å……/è§£ç åˆ†ç¦»ï¼ˆå¤§æ¨¡å‹ä¼˜åŒ–ï¼‰

```bash
# éƒ¨ç½²PrefillæœåŠ¡å™¨
helmfile apply -e prefill -n llm-d

# éƒ¨ç½²DecodeæœåŠ¡å™¨
helmfile apply -e decode -n llm-d

# éƒ¨ç½²è·¯ç”±ä¾§è½¦
helmfile apply -e sidecar -n llm-d
```

**é€‚ç”¨åœºæ™¯**: é•¿æç¤ºï¼ŒTTFTä¼˜åŒ–

### 3. å®½ä¸“å®¶å¹¶è¡Œï¼ˆMoEæ¨¡å‹ï¼‰

```bash
# éƒ¨ç½²InferencePool
helm install wide-ep-pool \
  --set modelServers.matchLabels.app=wide-ep \
  --set provider.name=istio \
  oci://registry.k8s.io/gateway-api-inference-extension/charts/inferencepool \
  -n llm-d

# éƒ¨ç½²æ¨¡å‹æœåŠ¡
helm install wide-ep-model \
  --set model.name=DeepSeek-R1 \
  --set role=wide_ep \
  oci://ghcr.io/llm-d-incubation/charts/llm-d-modelservice \
  -n llm-d
```

**é€‚ç”¨åœºæ™¯**: MoEæ¨¡å‹ï¼Œæœ€å¤§åå

## ğŸ”§ å¤šæ¨¡å‹æ”¯æŒ

### éƒ¨ç½²Body-Based Router

```bash
# å®‰è£…BBR
helm install body-based-router \
  --set provider.name=istio \
  oci://registry.k8s.io/gateway-api-inference-extension/charts/body-based-routing \
  -n llm-d
```

### é…ç½®å¤šæ¨¡å‹

```bash
# éƒ¨ç½²æ¨¡å‹A
helm install ms-model-a \
  --set model.name="Model-A-Name" \
  --set replicas=2 \
  oci://ghcr.io/llm-d-incubation/charts/llm-d-modelservice \
  -n llm-d

# éƒ¨ç½²æ¨¡å‹B
helm install ms-model-b \
  --set model.name="Model-B-Name" \
  --set replicas=3 \
  oci://ghcr.io/llm-d-incubation/charts/llm-d-modelservice \
  -n llm-d
```

## ğŸ¯ ç¡¬ä»¶é€‚é…

| ç¡¬ä»¶ç±»å‹ | éƒ¨ç½²å‘½ä»¤ | è¯´æ˜ |
|----------|----------|------|
| **GPU** | `helmfile apply -n llm-d` | é»˜è®¤é…ç½® |
| **CPU** | `helmfile apply -e cpu -n llm-d` | CPUæ¨ç† |
| **XPU** | `helmfile apply -e xpu -n llm-d` | Intel XPU |
| **TPU** | `helmfile apply -e gke_tpu -n llm-d` | Google TPU |
| **AWS** | `helmfile apply -e aws -n llm-d` | AWS EKS |

## ğŸ“Š æ€§èƒ½æµ‹è¯•

### åŸºç¡€æµ‹è¯•

```bash
# è·å–Gateway IP
GATEWAY_IP=$(kubectl get svc llm-d-infra-inference-gateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

# æµ‹è¯•æ¨ç†è¯·æ±‚
curl -X POST http://${GATEWAY_IP}/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen3-VL-235B-A22B-Instruct",
    "messages": [{"role": "user", "content": "Hello, world!"}]
  }'
```

### åŸºå‡†æµ‹è¯•

```bash
# ä½¿ç”¨å†…ç½®åŸºå‡†æµ‹è¯•å·¥å…·
cd llm-d-benchmark
python benchmark.py \
  --endpoint http://${GATEWAY_IP}/v1/chat/completions \
  --model "Qwen3-VL-235B-A22B-Instruct" \
  --requests 100 \
  --concurrency 10
```

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### å¿«é€Ÿè¯Šæ–­

```bash
# æ£€æŸ¥PodçŠ¶æ€
kubectl get pods -n llm-d
kubectl describe pod <pod-name> -n llm-d

# æ£€æŸ¥æ—¥å¿—
kubectl logs <epp-pod> | grep "Request handled"
kubectl logs <vllm-pod> | grep -i error

# æ£€æŸ¥æŒ‡æ ‡
kubectl port-forward <pod> 9090:9090
curl localhost:9090/metrics
```

### å¸¸è§é—®é¢˜

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| **Pod CrashLoopBackOff** | æ£€æŸ¥ConfigMapé…ç½® |
| **æ¨¡å‹åŠ è½½å¤±è´¥** | æ£€æŸ¥HF_TOKENå’ŒPVC |
| **è·¯ç”±å¤±è´¥** | éªŒè¯HTTPRouteé…ç½® |
| **æ€§èƒ½å·®** | æ£€æŸ¥GPUåˆ©ç”¨ç‡ |

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | ä¼˜ç§€ | å¯æ¥å— |
|------|------|----------|
| **TTFT** | <1s | <3s |
| **TPOT** | <50ms/token | <100ms/token |
| **ç¼“å­˜å‘½ä¸­ç‡** | >30% | >10% |
| **GPUåˆ©ç”¨ç‡** | >80% | >60% |

## ğŸ”„ ç‰ˆæœ¬ç®¡ç†

### å‡çº§éƒ¨ç½²

```bash
# è·å–æœ€æ–°ç‰ˆæœ¬
git fetch --tags
git checkout v0.4.0

# å‡çº§éƒ¨ç½²
helmfile apply -n llm-d
```

### å›æ»šéƒ¨ç½²

```bash
# å›æ»šåˆ°ç¨³å®šç‰ˆæœ¬
helm rollback <release-name> <revision> -n llm-d
```

### æ¸…ç†éƒ¨ç½²

```bash
# å¸è½½æ‰€æœ‰ç»„ä»¶
helmfile destroy -n llm-d

# æ¸…ç†å‘½åç©ºé—´
kubectl delete namespace llm-d
```

## ğŸ“š ä¸‹ä¸€æ­¥

- å‚è€ƒ[æ¶æ„æ€»è§ˆ](../architecture/01-overview.md)äº†è§£ç³»ç»Ÿæ¶æ„
- æŸ¥çœ‹[ç»„ä»¶è¯¦è§£](../components/)æ·±å…¥äº†è§£å„ç»„ä»¶
- é˜…è¯»[æ•…éšœæ’æŸ¥](../troubleshooting/01-common-issues.md)è§£å†³é—®é¢˜
- æ¢ç´¢[æœ€ä½³å®è·µ](#)ä¼˜åŒ–æ€§èƒ½
